gin <- unique(hunt$Haplotypes)
superb <- c()
for (hyati in gin) {
gta <- subset(hunt, hunt$Haplotypes %in% hyati)
gba <- data.frame(table(gta$groups))
if(nrow(gba) == 1){
gra <- as.character(gba$Var1)
names(gra) <- hyati
superb<- c(superb,gra)
}
else{
gra <- subset(gba, gba$Freq %in% max(gba$Freq))
gra <- as.character(gra[1,1])
names(gra) <- hyati
superb<- c(superb,gra)
}
}
superb <- data.frame(Haplotype = superb)
noofhap <- c()
for (jazz in 1:length(duncan_group)) {
good <- data.frame((duncan_group[[jazz]]))
doog <- data.frame(table(good$groups))
if( nrow(doog) == 1){
noofhap <- c(noofhap,"no")
}
else if( nrow(good) > 1){
#good <- subset(good, !good$Freq %in% "no")
#where <- good$groups
ome <- data.frame(table(good$groups))
uni <- ome[1:1,]
#funi <- tail(come,1)
appi <- uni$Var1
appi <- subset(good,good$groups %in% appi)
appi <- rownames(appi)
appi <- str_c(appi,collapse = ",")
#fh<- "yes"
noofhap <- c(noofhap,appi)
}
}
noofhap <-  unlist(str_split(noofhap,","))
uniq <- unique(noofhap)
noof <- str_count(noofhap,"no")
summy <- sum(noof)
uniq <- uniq[!uniq == "no"]
if ( summy >= 5){
happon <- c(happon, "no")
}
else {
counting <- c()
for (strcon in uniq) {
goop <- str_count(noofhap,strcon)
addi <- sum(goop)
names(addi) <- strcon
counting <- c(counting,addi)
}
ghij<- names(counting)
wwe <- subset(counting, counting %in% max(counting))
if ( length(wwe) > 1){
wwe <- paste(names(wwe), collapse = ",")
happon <- c(happon, wwe)
}
else{
happon <- c(happon,names(wwe))
}
}
summary<- Reduce(`+`, duncan_average)/length(duncan_average)
summary_final <- merge(summary, superb, by='row.names', all =T)
colnames(summary_final)[2] <- "Phenotype"
colnames(summary_final)[ncol(summary_final)] <- "group"
colnames(summary_final)[1] <- "Haplotypes"
summary_final$Location <- jun
SF[[jun]] <- summary_final
#summary<- cbind(hp,summary)
write.csv(summary,file.path(file = "summary.stat.csv"))
summ <- summary
colnames(summ)[1] <- "Means"
summ$Location <- jun
summ$Haplotype <- row.names(summ)
labels <- data.frame(duncan$groups)
labels$Haplotype<- row.names(labels)
labels<- labels[order(labels$Haplotype),]
hp <- subset(hp,hp$x%in% labels$Haplotype)
specify<- cbind(hp,labels)
mycolors = c(brewer.pal(name="BuGn", n = 9), brewer.pal(name="OrRd", n = 9),brewer.pal(name = "YlOrBr", n=9),brewer.pal(name = "Pastel1",n=9),brewer.pal(name = "Set1",n=9),brewer.pal(name="BuGn", n = 9), brewer.pal(name="OrRd", n = 9),brewer.pal(name = "YlOrBr", n=9),brewer.pal(name = "Pastel1",n=9),brewer.pal(name = "Set1",n=9))
jpeg(file.path(paste0(snpfile,".jpg")), height = 1200,width = 1400, res = 300)
p<-ggplot(sd, aes(x=Haplotype, y=sd[,2])) +labs(y=paste0(colnames(sd)[2]))+ geom_boxplot(aes(fill = factor(Haplotype)), show.legend = F,outlier.shape = NA)+scale_color_manual(values = mycolors, aesthetics = "fill")+ theme(axis.text.x = element_text(angle = 90, hjust= 1.0))
q<-p+geom_text(data = specify, aes(x,Inf, label= paste0("n=",Freq," ","(",groups,")"), angle = 90),hjust = 1.5,vjust = 1,size= 2.5)
r<- q+theme_bw()+theme(text = element_text(size=10, face="bold"),axis.text.x = element_text(angle = 90, hjust= 1.0))
s<- r + geom_jitter(shape=16, position=position_jitter(0.2), size = 0.5,color = "red")
t<- s+ggtitle(label = paste0(snpfile,""))
print(t)
dev.off()
draw <-sd
draw$Location <- jun
colnames(draw)[2] <- "Phenotype"
var_pop <- gsub('_', ' ', variety[,1])
variety_pop <- variety
variety_pop$names <- var_pop
variety_pop<- merge(variety_pop, pheno, by.x = 'names', by.y = 'Designation')
variety_pop<- variety_pop[order (variety_pop$group),]
variety_pop <- data.frame(variety_pop [,-c(1:1)])
colnames(variety_pop)[1] <- "Designation"
write.csv(variety_pop,file.path(file = "variety_subset.csv"),row.names = F)
count <- count(haplopheno$group)
colnames(count)<- c("x", "count_pop")
count$freq_pop <- count$count_pop/nrow(haplopheno)
hap<- cbind(row.names(haplo), haplo)
haplotype_pop<- merge(hap, count, by.x = 'row.names(haplo)', by.y = 'x' )
write.csv(haplotype_pop,file.path(file = "haplotype_subset.csv"),row.names = F)
gcc<- "all"
}
else {
sink(file.path( "no_anova.txt"))
print(" no duncan test can be performed contrasts can be applied only to factors with 2 or more levels")
sink()
gcc<- "NA"
}
}
icc<- gcc
if( gcc=="NA"){
#gcc<- "NA"
gc<- c(gc,gcc)
rm(gcc)
#rm(aooov)
}
else  if (nrow(table(duncan$groups$groups))>=2){
#drawing[[jun]] <- draw
#stata[[jun]] <- summ
beauty <- duncan$groups
come <- data.frame(table(duncan$groups$groups))
funi <- come[1:1,]
#funi <- tail(come,1)
happi <- funi$Var1
happi <- subset(beauty,beauty$groups %in% happi)
happi <- rownames(happi)
happi <- str_c(happi,collapse = ",")
#fh<- "yes"
gc<-c(gc,happi)
#rm(aooov)
#rm(duncan)
#rm(duncan.pval)
}
else {
hf<- "no"
gc<- c(gc,hf)
#rm(aooov)
#rm(duncan)
#rm(duncan.pval)
}
#rm(aooov)
drawing[[jun]] <- draw
stata[[jun]] <- summ
setwd(file.path(dir,gun))
}
source("~/Downloads/hap_phe_Updated.R", echo=TRUE)
source("~/Downloads/hap_phe_Updated.R", echo=TRUE)
source("~/Downloads/hap_phe_Updated.R", echo=TRUE)
source("~/Downloads/hap_phe_Updated.R", echo=TRUE)
gun
genes
sd <- hp.new
gc()
gen <- read.delim("~/Desktop/genes_list2.txt")
View(gen)
gen <- read.delim("~/Desktop/genes_list2.txt", header = F)
for (i in c(1:nrow(gen))) {
gene <- gen$V2[i]
file.copy(from = paste0(snpsift,gun,".csv"),to = paste0(getwd(),"/",gun,".csv"))
}
i <- 1
gun <- gen$V2[i]
paste0(snpsift,gun,".csv")
snpsift <- "/media/niran/Expansion/gwas_pipeline_June/snpsift/"
snpsift <- "/media/niran/Expansion/gwas_pipeline_June/snpsift/"
paste0(snpsift,gun,".csv")
paste0("~/Documents/gui_trail/data/snpsift/",gun,".csv")
gen <- read.delim("~/Desktop/genes_list2.txt", header = F)
snpsift <- "/media/niran/Expansion/gwas_pipeline_June/snpsift/"
for (i in c(1:nrow(gen))) {
gun <- gen$V2[i]
file.copy(from = paste0(snpsift,gun,".csv"),
to = paste0("~/Documents/gui_trail/data/snpsift/",gun,".csv"))
}
paste0(snpsift,gun,".csv")
# Run the application from GitHub repository
shiny::runGitHub(repo = "HaploGUI","IRRI-South-Asia-Hub")
runApp('Documents/geno_prep')
library(rsconnect)
runApp('Documents/geno_prep')
runApp('Documents/geno_prep')
runApp('Documents/geno_prep')
# Run the application from GitHub repository
shiny::runGitHub(repo = "HaploGUI","IRRI-South-Asia-Hub", destdir = "~/Documents/gui_trail/")
runApp('Documents/GitHub_PC/HaploGUI/HaploGUI')
runApp('Documents/geno_prep')
runApp('Documents/geno_prep')
library(rsconnect)
runApp('Documents/geno_prep')
runApp('Documents/geno_prep')
runApp('Documents/geno_prep')
ricegenes <- read.delim("~/Documents/gui_trail/ricegenes.txt")
View(ricegenes)
library(readxl)
keywords <- read_excel("Downloads/keywords.xlsx")
View(keywords)
out <- as.data.frame(keywords$MSU)
View(out)
fin <- merge(out,ricegenes, by.x = "keywords$MSU",by.y = "gene_id")
write.table(x = fin, file = "new_ricegenes.txt", row.names = F, col.names = T, sep = "\")
)
""
)
))))))))
asdlaufpoq23`7`
)
"
write.table(x = fin, file = "new_ricegenes.txt", row.names = F, col.names = T, sep = "\t", quote = F)
getwd()
shiny::runGitHub(repo = "HaploGUI","IRRI-South-Asia-Hub", destdir = "~/Documents/gui_trail/")
shiny::runGitHub(repo = "HaploGUI","IRRI-South-Asia-Hub", destdir = "~/Documents/gui_trail/")
runApp('Documents/GitHub_PC/HaploGUI/HaploGUI')
shiny::runGitHub(repo = "HaploGUI","IRRI-South-Asia-Hub", destdir = "~/Documents/gui_trail/")
shiny::runApp('Documents/geno_prep')
library(rsconnect)
shiny::runApp('Documents/HaploGUI_part2')
runApp('Documents/HaploGUI_part2')
shiny::runApp('Documents/HaploGUI_part2')
shiny::runGitHub(repo = "HaploGUI","IRRI-South-Asia-Hub", destdir = "~/Documents/delte_lat/")
shiny::runGitHub(repo = "HaploGUI","IRRI-South-Asia-Hub", destdir = "~/Documents/delte_lat/")
runApp('Documents/HaploGUI_part2')
runApp('Documents/HaploGUI_part2')
getwd()
del <- read.delim("~/Documents/HaploGUI_part2/del.csv")
View(del)
write.csv(del,file = "~/Documents/HaploGUI_part2/pheno_genoprep3.csv", row.names = F)
shiny::runGitHub(repo = "HaploGUI","IRRI-South-Asia-Hub",destdir = "~/Desktop/")
shiny::runGitHub(repo = "HaploGUI","IRRI-South-Asia-Hub",destdir = "D:/foldername/foldername2")
shiny::runGitHub(repo = "HaploGUI","IRRI-South-Asia-Hub",destdir = "~/Desktop/")
shiny::runGitHub(repo = "HaploGUI","IRRI-South-Asia-Hub",destdir = "~/Desktop/")
shiny::runGitHub(repo = "HaploGUI","IRRI-South-Asia-Hub",destdir = "~/Desktop/")
shiny::runApp('Downloads')
runApp('Downloads')
runApp('Downloads')
runApp('Downloads')
runApp('Downloads')
runApp('Downloads')
runApp('Downloads')
runApp('Downloads')
runApp('/media/niran/Expansion/HaploGUI_part2')
volumes <- c(Home = fs::path_home(), "R Installation" = R.home(), getVolumes()())
volumes
shinyFileChoose(input, "file", roots = volumes, session = session)
runApp('Downloads')
runApp('Downloads')
runApp('Downloads')
runApp('Downloads')
runApp('Downloads')
runApp('Downloads')
runApp('Downloads')
runApp('Downloads')
runApp('Downloads')
runApp('Downloads')
runApp('Downloads')
runApp('Downloads')
runApp('Downloads')
?shinyDirChoose
runApp('/media/niran/Expansion/HaploGUI_part2')
runApp('/media/niran/Expansion/HaploGUI_part2')
library(shiny); runApp('/media/niran/Expansion/HaploGUI_part2/app_etgwas2.R')
data_dir <- getwd()
paste0(data_dir,"/id.txt")
paste0(ip_dir, "plink2 --bfile marker_main --keep ",
data_dir,"/id.txt --export vcf --out ",data_dir,"/marker")
ip_dir <- getwd()
paste0(ip_dir, "plink2 --bfile marker_main --keep ",
data_dir,"/id.txt --export vcf --out ",data_dir,"/marker")
paste0(ip_dir, "/plink2 --bfile marker_main --keep ",
data_dir,"/id.txt --export vcf --out ",data_dir,"/marker")
runApp('/media/niran/Expansion/HaploGUI_part2/app_etgwas2.R')
runApp('/media/niran/Expansion/HaploGUI_part2/app_etgwas2.R')
paste0(ip_dir,"/tassel-5-standalone/run_pipeline.pl -fork1 -vcf ",
data_dir,"/marker.vcf -export ",data_dir,"/marker -exportType Hapmap")
paste0(data_dir,"/marker.hmp.txt")
paste0(data_dir,"/marker.csv")
paste0(ip_dir, "/plink2 --vcf ",
data_dir,"/marker.vcf --pca --read-freq ",
data_dir,"/freq.afreq --out ",data_dir,"/pca")
paste0(ip_dir, "/plink2 --vcf ",
data_dir,"/marker.vcf --freq --out ",data_dir,"/freq")
shiny::runApp('/media/niran/Expansion/Et-GWAS_from the server')
getwd()
setwd("/media/niran/Expansion/Et-GWAS_from the server/")
runApp()
shiny::runApp()
runApp()
i <- 1
infile <- paste0(trait,"_",bulks[i],perc,".ped")
trait <- "try"
infile <- paste0(trait,"_",bulks[i],perc,".ped")
bulks <- c("high","low","rand")
infile <- paste0(trait,"_",bulks[i],perc,".ped")
perc <- 10
infile <- paste0(trait,"_",bulks[i],perc,".ped")
c <- read.delim(infile, header = F, sep = " ",colClasses = c("character"))
d <- c[,c(7:ncol(c))]
try_high10 <- read.delim("F:/Et-GWAS_from the server/try_high10.ped", header=FALSE)
View(try_high10)
c <- read.delim(infile, header = F, colClasses = c("character"))
remove(c)
c <- read.delim(infile, header = F, colClasses = c("character"))
d <- c[,c(7:ncol(c))]
pooling_snp <- function(i){
infile <- paste0(trait,"_",bulks[i],perc,".ped")
c <- read.delim(infile, header = F, colClasses = c("character"))
d <- c[,c(7:ncol(c))]
out <- apply(d, 2, function(x){
run = rle(sort(x[x!=0]))
if(length(run$lengths) < 2){
run$lengths[2] <- 0
run$values[2] <- 0
}
g <- stack(run)[1]
})
lstData <- Map(as.data.frame, out)
dfrData <- rbindlist(lstData)
count_cols <- sort(c(seq(1,nrow(dfrData),4),seq(2,nrow(dfrData),4)))
all_cols <- sort(c(seq(3,nrow(dfrData),4),seq(4,nrow(dfrData),4)))
df <- dfrData[count_cols]
df$all <- dfrData[all_cols]
colhead <- data.frame(rep(seq(1,(nrow(df)/4)), each=4))
colnames(colhead) <- "num"
comb <- cbind(colhead,df)
comb$values <- as.numeric(comb$values)
comb$alle <- paste(comb$num, comb$all, sep = "_")
comb <- comb[comb$all != 0,]
out <- comb %>% dplyr::group_by(alle) %>%
dplyr::summarize(tot = sum(values), nums = unique(num), .groups = 'drop')
outfile <- paste0("temp_",bulks[i],".csv")
write.csv(out, outfile, row.names = F)
}
cl<- detectCores()
registerDoParallel(cl)
result <- foreach (i=1:3) %dopar% {
pooling_snp(i)
}
stopImplicitCluster()
i
?rbindlist
library(data.table)
cl<- detectCores()
registerDoParallel(cl)
result <- foreach (i=1:3) %dopar% {
pooling_snp(i)
}
stopImplicitCluster()
rbindlist()
i <- 1
runApp()
library(data.table)
library(stringr)
lstData <- Map(as.data.frame, out)
runApp()
lstData <- Map(as.data.frame, out)
bulks <- c("high","low","rand")
i <- 1
infile <- paste0(trait,"_",bulks[i],perc,".ped")
trait <- "try"
infile <- paste0(trait,"_",bulks[i],perc,".ped")
perc <- 10
infile <- paste0(trait,"_",bulks[i],perc,".ped")
c <- read.delim(infile, header = F, colClasses = c("character"))
d <- c[,c(7:ncol(c))]
out <- apply(d, 2, function(x){
run = rle(sort(x[x!=0]))
if(length(run$lengths) < 2){
run$lengths[2] <- 0
run$values[2] <- 0
}
g <- stack(run)[1]
})
lstData <- Map(as.data.frame, out)
dfrData <- rbindlist(lstData)
count_cols <- sort(c(seq(1,nrow(dfrData),4),seq(2,nrow(dfrData),4)))
all_cols <- sort(c(seq(3,nrow(dfrData),4),seq(4,nrow(dfrData),4)))
df <- dfrData[count_cols]
df$all <- dfrData[all_cols]
colhead <- data.frame(rep(seq(1,(nrow(df)/4)), each=4))
colnames(colhead) <- "num"
comb <- cbind(colhead,df)
comb$values <- as.numeric(comb$values)
comb$alle <- paste(comb$num, comb$all, sep = "_")
comb <- comb[comb$all != 0,]
out <- comb %>% dplyr::group_by(alle) %>%
dplyr::summarize(tot = sum(values), nums = unique(num), .groups = 'drop')
outfile <- paste0("temp_",bulks[i],".csv")
write.csv(out, outfile, row.names = F)
i <- 2
infile <- paste0(trait,"_",bulks[i],perc,".ped")
c <- read.delim(infile, header = F, colClasses = c("character"))
d <- c[,c(7:ncol(c))]
out <- apply(d, 2, function(x){
run = rle(sort(x[x!=0]))
if(length(run$lengths) < 2){
run$lengths[2] <- 0
run$values[2] <- 0
}
g <- stack(run)[1]
})
lstData <- Map(as.data.frame, out)
dfrData <- rbindlist(lstData)
count_cols <- sort(c(seq(1,nrow(dfrData),4),seq(2,nrow(dfrData),4)))
all_cols <- sort(c(seq(3,nrow(dfrData),4),seq(4,nrow(dfrData),4)))
df <- dfrData[count_cols]
df$all <- dfrData[all_cols]
colhead <- data.frame(rep(seq(1,(nrow(df)/4)), each=4))
colnames(colhead) <- "num"
comb <- cbind(colhead,df)
comb$values <- as.numeric(comb$values)
comb$alle <- paste(comb$num, comb$all, sep = "_")
comb <- comb[comb$all != 0,]
out <- comb %>% dplyr::group_by(alle) %>%
dplyr::summarize(tot = sum(values), nums = unique(num), .groups = 'drop')
outfile <- paste0("temp_",bulks[i],".csv")
write.csv(out, outfile, row.names = F)
i <- 3
infile <- paste0(trait,"_",bulks[i],perc,".ped")
c <- read.delim(infile, header = F, colClasses = c("character"))
d <- c[,c(7:ncol(c))]
out <- apply(d, 2, function(x){
run = rle(sort(x[x!=0]))
if(length(run$lengths) < 2){
run$lengths[2] <- 0
run$values[2] <- 0
}
g <- stack(run)[1]
})
lstData <- Map(as.data.frame, out)
dfrData <- rbindlist(lstData)
count_cols <- sort(c(seq(1,nrow(dfrData),4),seq(2,nrow(dfrData),4)))
all_cols <- sort(c(seq(3,nrow(dfrData),4),seq(4,nrow(dfrData),4)))
df <- dfrData[count_cols]
df$all <- dfrData[all_cols]
colhead <- data.frame(rep(seq(1,(nrow(df)/4)), each=4))
colnames(colhead) <- "num"
comb <- cbind(colhead,df)
comb$values <- as.numeric(comb$values)
comb$alle <- paste(comb$num, comb$all, sep = "_")
comb <- comb[comb$all != 0,]
out <- comb %>% dplyr::group_by(alle) %>%
dplyr::summarize(tot = sum(values), nums = unique(num), .groups = 'drop')
outfile <- paste0("temp_",bulks[i],".csv")
write.csv(out, outfile, row.names = F)
cl<- detectCores()
registerDoParallel(cl)
result <- foreach (i=1:3) %dopar% {
pooling_snp(i)
}
pooling_snp <- function(i){
infile <- paste0(trait,"_",bulks[i],perc,".ped")
c <- read.delim(infile, header = F, colClasses = c("character"))
d <- c[,c(7:ncol(c))]
out <- apply(d, 2, function(x){
run = rle(sort(x[x!=0]))
if(length(run$lengths) < 2){
run$lengths[2] <- 0
run$values[2] <- 0
}
g <- stack(run)[1]
})
lstData <- Map(as.data.frame, out)
dfrData <- rbindlist(lstData)
count_cols <- sort(c(seq(1,nrow(dfrData),4),seq(2,nrow(dfrData),4)))
all_cols <- sort(c(seq(3,nrow(dfrData),4),seq(4,nrow(dfrData),4)))
df <- dfrData[count_cols]
df$all <- dfrData[all_cols]
colhead <- data.frame(rep(seq(1,(nrow(df)/4)), each=4))
colnames(colhead) <- "num"
comb <- cbind(colhead,df)
comb$values <- as.numeric(comb$values)
comb$alle <- paste(comb$num, comb$all, sep = "_")
comb <- comb[comb$all != 0,]
out <- comb %>% dplyr::group_by(alle) %>%
dplyr::summarize(tot = sum(values), nums = unique(num), .groups = 'drop')
outfile <- paste0("temp_",bulks[i],".csv")
write.csv(out, outfile, row.names = F)
}
stopImplicitCluster()
cl<- detectCores()
registerDoParallel(cl)
result <- foreach (i=1:3) %dopar% {
pooling_snp(i)
}
stopImplicitCluster()
result <- for(i in c(1:3)){
pooling_snp(i)
}
out_low <- read.csv("temp_low.csv")
out_high <- read.csv("temp_high.csv")
out_rand <- read.csv("temp_rand.csv")
temp <- merge(out_high,out_low, by = "alle", all = T)
comb <- merge(temp,out_rand, by = "alle", all = T)
out <- comb[order(comb$nums.x),c(1,2,4,6,7)]
colnames(out) <- c("RefAlt", "high" ,"low","random","num")
# Ref and Alt alleles From HapMap -----------------------------------------
hmpfile <- paste0(infam,"_hmp_allele.txt")
runApp()
list_of_packages = c("shiny","shinyjs","shinythemes","crayon","ggplot2",
"ggridges","dplyr","ggfortify","ggpubr",
"extrafont","data.table","stringr","CMplot",
"MASS","zip","tidyr","tidyverse","RColorBrewer")
lapply(list_of_packages,
function(x) if(!require(x,character.only = TRUE)) install.packages(x))
